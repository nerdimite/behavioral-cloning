{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms as tfms\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "data_df = pd.read_csv('training_data_plains/driving_log.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_path(path):\n",
    "#     return re.sub(re.escape(os.path.normpath(\"\\\\\")), '/', path[31:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     data_df[i] = data_df[i].map(format_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the center, left and right as X data and the steering angle as y data\n",
    "X = data_df[[0,1,2]].values\n",
    "y = data_df[3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length: 14756\n",
      "Val Length: 7268\n"
     ]
    }
   ],
   "source": [
    "print('Train Length:',len(X_train))\n",
    "print('Val Length:',len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# steering angle histogram\n",
    "plt.hist(y_train, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Augmentation\n",
    "\n",
    "* augmentation\n",
    "    * choose center | left | right\n",
    "    * flip\n",
    "    * brightness\n",
    "* preprocess\n",
    "* batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_image(image_paths, steering_angle):\n",
    "    '''Choose center | left | right and adjust the steering angle accordingly'''\n",
    "    \n",
    "    choice = np.random.choice(3)\n",
    "    \n",
    "    if choice == 0: # left\n",
    "        return cv2.imread(image_paths[1].strip()), steering_angle + 0.2\n",
    "    \n",
    "    elif choice == 1: # right\n",
    "        return cv2.imread(image_paths[2].strip()), steering_angle - 0.2\n",
    "    \n",
    "    return cv2.imread(image_paths[0].strip()), steering_angle # center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, steering_angle):\n",
    "    '''Randomly flip the image horizontally and adjust steering angle'''\n",
    "    \n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_brightness(image):\n",
    "    '''Randomly increase or decrease brightness'''\n",
    "    \n",
    "    choice = np.random.choice(2)\n",
    "    \n",
    "    if choice == 1:\n",
    "        return image + np.random.randint(1,20)\n",
    "    \n",
    "    return image - np.random.randint(0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image_paths, steering_angle):\n",
    "    '''Generate an augmented image'''\n",
    "\n",
    "    image, steering_angle = choose_image(image_paths, steering_angle)\n",
    "\n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    image = random_brightness(image)\n",
    "    \n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    '''Preprocess an image by cropping, resizing and tensorizing'''\n",
    "    img = img[60:-25,:]\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    img = tfms.ToTensor()(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_data, y_data, batch_size, is_training=True):\n",
    "    '''Generate Training Data'''\n",
    "    \n",
    "    images = torch.empty([batch_size, 3, 66, 200])\n",
    "    steers = torch.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for idx in np.random.permutation(X_data.shape[0]):\n",
    "            image_paths = X_data[idx]\n",
    "            steering_angle = y_data[idx]\n",
    "\n",
    "            # randomly decide to augment or not\n",
    "            if is_training and np.random.rand() < 0.5:\n",
    "                image, steering_angle = augmentation(image_paths, steering_angle)\n",
    "            else:\n",
    "                image = cv2.imread(image_paths[0])\n",
    "\n",
    "            images[i] = preprocess_image(image)\n",
    "            steers[i] = steering_angle\n",
    "\n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "            \n",
    "        yield images, steers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NvidiaModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 24, 5, 2)\n",
    "        self.conv2 = nn.Conv2d(24, 36, 5, 2)\n",
    "        self.conv3 = nn.Conv2d(36, 48, 5, 2)\n",
    "        self.conv4 = nn.Conv2d(48, 64, 3, 1)\n",
    "        self.conv5 = nn.Conv2d(64, 64, 3, 1)\n",
    "        \n",
    "        self.dense = nn.Sequential(nn.Linear(1152, 100),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Dropout(0.25),\n",
    "                                   nn.Linear(100, 50),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Linear(50, 10),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Linear(10, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Convolutional Pass\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = F.elu(self.conv4(x))\n",
    "        x = F.elu(self.conv5(x))\n",
    "        \n",
    "        # Linear Pass\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        out = self.dense(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NvidiaModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma=0.5, step_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer, \n",
    "          scheduler,\n",
    "          tag,\n",
    "          train_steps=5000,\n",
    "          validation_steps=1000,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          device='cuda'):\n",
    "    \n",
    "    # push to model to the device (CUDA or CPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Create Data Generators\n",
    "    train_loader = batch_generator(X_train, y_train, batch_size)\n",
    "    val_loader = batch_generator(X_val, y_val, batch_size, is_training=False)\n",
    "    \n",
    "    # Directory for saving model\n",
    "    if not os.path.isdir('models'):\n",
    "        os.mkdir('models')\n",
    "    \n",
    "    for current_epoch in range(1, epochs+1):\n",
    "        \n",
    "        # TRAIN\n",
    "        pbar = tqdm(desc=f\"Training Epoch {current_epoch}\", total=train_steps)\n",
    "        model.train()\n",
    "        \n",
    "        for i in range(train_steps):\n",
    "            images, steers = next(train_loader)\n",
    "            \n",
    "            images = images.to(device)\n",
    "            steers = steers.to(device)\n",
    "            \n",
    "            # set the optimizer to zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # pass the inputs through the model\n",
    "            outputs = model(images)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(outputs.squeeze(1), steers)\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Train Loss': loss.item()\n",
    "            })\n",
    "            pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "        # VALIDATION\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            val_pbar = tqdm(desc=f\"Validation Epoch {current_epoch}\", total=validation_steps)\n",
    "            \n",
    "            val_losses = []\n",
    "            \n",
    "            for i in range(validation_steps):\n",
    "                images, steers = next(val_loader)\n",
    "                # move the data to selected device\n",
    "                images = images.to(device)\n",
    "                steers = steers.to(device)\n",
    "\n",
    "                # pass the inputs through the model\n",
    "                outputs = model(images)\n",
    "\n",
    "                # calculate loss\n",
    "                loss = criterion(outputs.squeeze(1), steers)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                val_pbar.set_postfix({\n",
    "                    'Val Loss': loss.item()\n",
    "                })\n",
    "                val_pbar.update(1)\n",
    "            \n",
    "            mean_val_loss = sum(val_losses)/len(val_losses)\n",
    "        \n",
    "        val_pbar.set_postfix({\n",
    "            'Avg Val Loss': mean_val_loss\n",
    "        })\n",
    "        val_pbar.close()\n",
    "        \n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), f'models/model-{current_epoch}-{tag}.pth')\n",
    "    \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(model, criterion, optimizer, scheduler, tag='plains', epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
