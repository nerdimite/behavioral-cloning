{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "data_df = pd.read_csv('data/driving_log.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the center, left and right as X data and the steering angle as y data\n",
    "X = data_df[[0,1,2]].values\n",
    "y = data_df[3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length: 12567\n",
      "Val Length: 6190\n"
     ]
    }
   ],
   "source": [
    "print('Train Length:',len(X_train))\n",
    "print('Val Length:',len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# steering angle histogram\n",
    "plt.hist(y_train, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Augmentation\n",
    "\n",
    "* augmentation\n",
    "    * choose center | left | right\n",
    "    * flip\n",
    "    * brightness\n",
    "* preprocess\n",
    "* batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_image(image_paths, steering_angle):\n",
    "    '''Choose center | left | right and adjust the steering angle accordingly'''\n",
    "    \n",
    "    choice = np.random.choice(3)\n",
    "    \n",
    "    if choice == 0: # left\n",
    "        return cv2.imread(image_paths[1].strip()), steering_angle + 0.2\n",
    "    \n",
    "    elif choice == 1: # right\n",
    "        return cv2.imread(image_paths[2].strip()), steering_angle - 0.2\n",
    "    \n",
    "    return cv2.imread(image_paths[0].strip()), steering_angle # center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, steering_angle):\n",
    "    '''Randomly flip the image horizontally and adjust steering angle'''\n",
    "    \n",
    "    if np.random.rand() < 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering_angle = -steering_angle\n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_brightness(image):\n",
    "    '''Randomly increase or decrease brightness'''\n",
    "    \n",
    "    choice = np.random.choice(2)\n",
    "    \n",
    "    if choice == 1:\n",
    "        return image + np.random.randint(1,20)\n",
    "    \n",
    "    return image - np.random.randint(0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image_paths, steering_angle):\n",
    "    '''Generate an augmented image'''\n",
    "    \n",
    "    image, steering_angle = choose_image(image_paths, steering_angle)\n",
    "    \n",
    "    image, steering_angle = random_flip(image, steering_angle)\n",
    "    image = random_brightness(image)\n",
    "    \n",
    "    return image, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    '''Preprocess an image by cropping and resizing'''\n",
    "    img = img[60:-25,:]\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_data, y_data, batch_size, is_training=True):\n",
    "    '''Generate Training Data'''\n",
    "    \n",
    "    images = np.empty([batch_size, 66, 200, 3])\n",
    "    steers = np.empty(batch_size)\n",
    "    while True:\n",
    "        i = 0\n",
    "        for idx in np.random.permutation(X_data.shape[0]):\n",
    "            image_paths = X_data[idx]\n",
    "            steering_angle = y_data[idx]\n",
    "            \n",
    "            # randomly decide to augment or not\n",
    "            if is_training and np.random.rand() < 0.5:\n",
    "                image, steering_angle = augmentation(image_paths, steering_angle)\n",
    "            else:\n",
    "                image = cv2.imread(image_paths[0])\n",
    "            \n",
    "            images[i] = preprocess_image(image)\n",
    "            steers[i] = steering_angle\n",
    "            \n",
    "            i += 1\n",
    "            if i == batch_size:\n",
    "                break\n",
    "        yield images, steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(img):\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display an augmented image\n",
    "# # itest = cv2.imread(X[432][0].strip())\n",
    "# itest, _ = augmentation(X[432], y[432])\n",
    "# itest = preprocess_image(itest)\n",
    "# display_image(itest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Lambda, Convolution2D\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NvidiaModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              (None, 66, 200, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 31, 98, 24)        1824      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 47, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 22, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 20, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 18, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='NvidiaModel')\n",
    "\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(66,200,3)))      \n",
    "\n",
    "# 24 filters, kernel size = 5x5, stride = 2x2\n",
    "model.add(Convolution2D(24,5,2, activation='elu'))\n",
    "\n",
    "# 36 filters, kernel size = 5x5, stride = 2x2\n",
    "model.add(Convolution2D(36,5,2, activation='elu'))\n",
    "\n",
    "# 48 filters, kernel size = 5x5, stride = 2x2\n",
    "model.add(Convolution2D(48,5,2, activation='elu'))\n",
    "\n",
    "# 64 filters, kernel size = 3x3, stride = 1x1\n",
    "model.add(Convolution2D(64,3, activation='elu'))\n",
    "\n",
    "# 64 filters, kernel size = 3x3, stride = 1x1\n",
    "model.add(Convolution2D(64,3, activation='elu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(50, activation='elu'))\n",
    "\n",
    "model.add(Dense(10, activation='elu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:02d}-{val_loss:.3f}.h5',\n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "STEPS_PER_EPOCH = 5000\n",
    "VALIDATION_STEPS = 1000\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 0.0378\n",
      "Epoch 00001: saving model to model-01-0.028.h5\n",
      "5000/5000 [==============================] - 717s 143ms/step - loss: 0.0378 - val_loss: 0.0282\n",
      "Epoch 2/5\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 0.0344\n",
      "Epoch 00002: saving model to model-02-0.028.h5\n",
      "5000/5000 [==============================] - 676s 135ms/step - loss: 0.0344 - val_loss: 0.0277\n",
      "Epoch 3/5\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 0.0336\n",
      "Epoch 00003: saving model to model-03-0.029.h5\n",
      "5000/5000 [==============================] - 644s 129ms/step - loss: 0.0336 - val_loss: 0.0290\n",
      "Epoch 4/5\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 0.0335\n",
      "Epoch 00004: saving model to model-04-0.028.h5\n",
      "5000/5000 [==============================] - 479s 96ms/step - loss: 0.0335 - val_loss: 0.0279\n",
      "Epoch 5/5\n",
      "4999/5000 [============================>.] - ETA: 0s - loss: 0.0322\n",
      "Epoch 00005: saving model to model-05-0.029.h5\n",
      "5000/5000 [==============================] - 464s 93ms/step - loss: 0.0322 - val_loss: 0.0287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23df6ea2a08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batch_generator(X_train, y_train, BATCH_SIZE), \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    epochs=EPOCHS, \n",
    "                    callbacks=[checkpoint], \n",
    "                    validation_data=batch_generator(X_val, y_val, BATCH_SIZE, is_training=False), \n",
    "                    validation_steps=VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
